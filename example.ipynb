{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing dimension orders.\n",
      "GRE Score: Ascending (0.47)\n",
      "TOEFL Score: Ascending (0.61)\n",
      "University Rating: Descending (-0.15)\n",
      "SOP: Descending (-0.36)\n",
      "LOR : Ascending (0.74)\n",
      "CGPA: Ascending (1.77)\n",
      "Research: Ascending (0.02)\n",
      "Computing the forcing relation on cases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 2385.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The consistency is 456 / 500 = 91.2%.\n",
      "Of the 39 cases with label 0 there are 8 inconsistent ones.\n",
      "Of the 461 cases with label 1 there are 36 inconsistent ones.\n",
      "Computing best citability information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 237.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PR] Mean and std. of best citability is 50.5 ± 100.2.\n",
      "Top forcing landmark with outcome 0:\n",
      "-------------------------------\n",
      "d                  c[d].value\n",
      "-----------------  ------------\n",
      "GRE Score          316\n",
      "TOEFL Score        105\n",
      "University Rating  2\n",
      "SOP                2.5\n",
      "LOR                2.5\n",
      "CGPA               8.2\n",
      "Research           1\n",
      "-------------------------------\n",
      "Outcome: 0.0\n",
      "-------------------------------\n",
      "Top forcing landmark with outcome 1:\n",
      "-------------------------------\n",
      "d                  c[d].value\n",
      "-----------------  ------------\n",
      "GRE Score          304\n",
      "TOEFL Score        103\n",
      "University Rating  5\n",
      "SOP                5\n",
      "LOR                3\n",
      "CGPA               7.92\n",
      "Research           0\n",
      "-------------------------------\n",
      "Outcome: 1.0\n",
      "-------------------------------\n",
      "\n",
      "Number of landmarks for outcome 0: 23\n",
      "Number of landmarks for outcome 1: 67\n",
      "\n",
      "Number of ordinary (aka trivial) cases for either class:\n",
      "For outcome 0: 39 - 23 = 16\n",
      "For outcome 1: 461 - 67 = 394\n",
      "Removals to obtain cons.: 8/500 = 1.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from CBR.casebase import *\n",
    "\n",
    "small_sets = False\n",
    "size = 300 if small_sets else -1\n",
    "\n",
    "# A link to the (processed) csv file. \n",
    "# Feel free to try some different values. \n",
    "# csv = \"data/mushrooms.csv\"\n",
    "csv = \"data/admission.csv\"\n",
    "# csv = \"data/tort.csv\"\n",
    "# csv = \"data/welfare.csv\"\n",
    "\n",
    "# Load the case base with logistic regression orders.\n",
    "CB = casebase(\n",
    "    csv,\n",
    "    verb=True, # The verbose mode prints the dimension order information. \n",
    "    method='logreg',\n",
    "    size=size, # Truncates the size of the resulting case base to 'size', \n",
    "               # or uses the full size of the csv if size == -1. \n",
    "    shuffle=True,\n",
    "    )\n",
    "\n",
    "# 'analyze' is a conenience functions that bundles the other analysis functions,\n",
    "# check the casebase.py file to see (or change) what it does.\n",
    "CB.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension              a   R   b       F\n",
      "-----------------  -----  ---  -----  ---\n",
      "GRE Score          310.0   >   305.0   X\n",
      "TOEFL Score         99.0   <   107.0\n",
      "University Rating    2.0   =   2.0\n",
      "SOP                  1.5   >   2.5     X\n",
      "LOR                  2.0   <   2.5\n",
      "CGPA                 7.3   <   8.42\n",
      "Research             0.0   =   0.0\n",
      "Label                1.0       1.0\n",
      "['GRE Score', 'SOP']\n"
     ]
    }
   ],
   "source": [
    "# Load the first two cases in the case base in variables a and b. \n",
    "a = CB[1]\n",
    "b = CB[7]\n",
    "\n",
    "# Print a comparison between the cases a and b.\n",
    "# This shows for each dimension d the values a(d) and b(d),\n",
    "# the relation between them (so a(d) < b(d), or a(d) > b(d), etc).\n",
    "CB.compare(a, b)\n",
    "\n",
    "# Dimensions on which b is not better than a are called 'relevant differences.\n",
    "# These can be computer with the .diff function of cases.\n",
    "# Note that these are also indicated by the 'compare' function.\n",
    "relevant_differences = a.diff(b)\n",
    "print(list(relevant_differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outcome of the input case a was forced by a case b in the case base:\n",
      "Dimension              a   R   b       F\n",
      "-----------------  -----  ---  -----  ---\n",
      "GRE Score          315.0   >   314.0\n",
      "TOEFL Score        105.0   =   105.0\n",
      "University Rating    2.0   =   2.0\n",
      "SOP                  2.0   >   2.5\n",
      "LOR                  2.5   >   2.0\n",
      "CGPA                7.65   >   7.64\n",
      "Research             0.0   =   0.0\n",
      "Label                0.0       1.0\n"
     ]
    }
   ],
   "source": [
    "# As we know, if c has outcome s then c forces the outcome of d for s iff D(c, d) = {}. \n",
    "# This means we can use the .diff function to check whether a CB forces the outcome of a case.\n",
    "a = CB[3] # change to CB[0] for an example of a case that was not forced. \n",
    "force = False\n",
    "for b in CB:\n",
    "    if not a == b:\n",
    "        if list(b.diff(a)) == []:\n",
    "            force = True\n",
    "            print(\"The outcome of the input case a was forced by a case b in the case base:\")\n",
    "            CB.compare(b, a)\n",
    "            break\n",
    "\n",
    "if not force:\n",
    "    print(\"The outcome of case a was not forced by CB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of CB: 500\n",
      "Taking first 400 for train, and 100 for test.\n",
      "The outcome of the input case a was forced by a case b in the training case base:\n",
      "-------------------------------\n",
      "d                  c[d].value\n",
      "-----------------  ------------\n",
      "GRE Score          335\n",
      "TOEFL Score        117\n",
      "University Rating  5\n",
      "SOP                5\n",
      "LOR                5\n",
      "CGPA               9.56\n",
      "Research           1\n",
      "-------------------------------\n",
      "Outcome: 1.0\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "d                  c[d].value\n",
      "-----------------  ------------\n",
      "GRE Score          304\n",
      "TOEFL Score        103\n",
      "University Rating  5\n",
      "SOP                5\n",
      "LOR                3\n",
      "CGPA               7.92\n",
      "Research           0\n",
      "-------------------------------\n",
      "Outcome: 1.0\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compute the size of the case base, and make a ~80% split. \n",
    "CB_size = len(list(CB.inds))\n",
    "split = CB_size - (CB_size // 5)\n",
    "CB_train = CB[:split]\n",
    "CB_test = CB[split:]\n",
    "print(f\"Total size of CB: {CB_size}\")\n",
    "print(f\"Taking first {split} for train, and {CB_size - split} for test.\")\n",
    "\n",
    "# Compute whether the first case of the test split is forced by the train split. \n",
    "a = CB_train[0]\n",
    "for b in CB_train:\n",
    "    if not a == b:\n",
    "        if list(b.diff(a)) == []:\n",
    "            force = True\n",
    "            print(\"The outcome of the input case a was forced by a case b in the training case base:\")\n",
    "            print(a)\n",
    "            print(b)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "068e3009dfa64c1a6fa42da4ad82f467b0844a8a0e6fa977c7f6dfa35a691984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
